{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b079b26-ef7d-44cc-8a14-eee8963538cb",
   "metadata": {},
   "source": [
    "I was studying German the other day and stumbled upon a typo that leads me an interesting observation on these two words:\n",
    "\n",
    "- [anschließen](https://en.wiktionary.org/wiki/anschlie%C3%9Fen#German) (to connect)\n",
    "- [anschließend](https://en.wiktionary.org/wiki/anschlie%C3%9Fend#German) (following, afterwards)\n",
    "\n",
    "They are very \"similar\" and I would like them to be connected in [wilhelmlang.com](https://wilhelmlang.com/), a platform that helps language learner learn multi-languages via knowledge graph.\n",
    "\n",
    "We define the similarity of two words in this context as follows:\n",
    "\n",
    "___Two words are similar either structurally or semantically___.\n",
    "\n",
    "For example:\n",
    "\n",
    "- __anschließen__ and __anschließend__ are structually similar because they differ by just one character (trailing __d__).\n",
    "- __anschließend__ and [__nachher__](https://en.wiktionary.org/wiki/nachher#German), are semantically similar because they both mean __afterwards__ as adverb\n",
    "- Some can possess both. For instance, [__das Theater__](https://en.wiktionary.org/wiki/Theater#German) (the theater) and [__das Theaterstück__](https://en.wiktionary.org/wiki/Theaterst%C3%BCck#German) (the drama) are similar both semantically and structurally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24027445-317b-4124-96a9-3da581eaced6",
   "metadata": {},
   "source": [
    "### Lavenshtien's Distance\n",
    "\n",
    "The first idea was to calculating the similarity between two words\n",
    "\n",
    "The closest would be like the [Levenstein's distance](https://en.wikipedia.org/wiki/Levenshtein_distance) (also popularly called the _edit distance_).\n",
    "\n",
    "> In information theory and computer science, the Levenshtein distance is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (i.e. insertions, deletions or substitutions) required to change one word into the other.\n",
    "\n",
    "In information theory and computer science, the Levenshtein distance is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (i.e. insertions, deletions or substitutions) required to change one word into the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9baf248-9a8b-41c7-94ad-a45e23561e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.edit_distance(\"anschließen\", \"anschließend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf5be91-9a2f-4ae7-bc6f-ce7384aa15ea",
   "metadata": {},
   "source": [
    "The code above would return 1, as only one letter is different between the two words. Lavenshtien's distance is good for spotting the __anschließen-anschließend__ case\n",
    "\n",
    "The __anschließend-nachher__ won't work well with the edit distance, though. We need a different metric approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a795a63a-2694-4976-89dd-d72903bc77d7",
   "metadata": {},
   "source": [
    "### Cosin Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de5bb6a-167f-4227-8e22-e1bf0add78d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "spaCy : 0.33368661999702454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4n/bzxtzt1j1wv4pyljc9bc2tm80000gn/T/ipykernel_30575/3179405924.py:10: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(\"spaCy :\", doc1.similarity(doc2))\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.cli.download('de_core_news_sm')\n",
    "\n",
    "nlp = spacy.load('de_core_news_sm') \n",
    "  \n",
    "text1 = 'anschließend'\n",
    "text2 = 'nachher'\n",
    "doc1 = nlp(text1)\n",
    "doc2 = nlp(text2)\n",
    "print(\"spaCy :\", doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec1ef34-3cb3-486a-99f3-caccece95488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
