{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58db62a5",
   "metadata": {},
   "source": [
    "Overview\n",
    "-----------\n",
    "\n",
    "This notebook use [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database), which is a set of 70,000 small images of digits handwritten by high school students and employees of the US Census Bureau, for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "139c6987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False) # https://github.com/ageron/handson-ml2/issues/518#issuecomment-1001289203\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b8177",
   "metadata": {},
   "source": [
    "Datasets loaded by scikit-learn generally have a similar dictionary structure, including the following:\n",
    "\n",
    "- A `DESCR` key describing the dataset\n",
    "- A `data` key containing an array with one row per instance and one column per feature\n",
    "- A `target` key containing an array with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05a01c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 70000 images, and each image has 784 features. This is because each image is 28 × 28 pixels, and each feature simply represents one pixel’s intensity, from 0 (white) to 255 (black).\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "data, labels = mnist[\"data\"], mnist[\"target\"]\n",
    "data.shape\n",
    "\n",
    "print(\n",
    "    \"There are {0} images, and each image has {1} features. \".format(data.shape[0], data.shape[1]) +\n",
    "    \"This is because each image is {0} × {0} pixels, and each feature simply represents one pixel’s intensity, from 0 (white) to 255 (black).\".format(int(math.sqrt(data.shape[1])))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde5f54",
   "metadata": {},
   "source": [
    "Let’s take a peek at one digit from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "255fd538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAP3RFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMS5wb3N0MSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8kixA/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAIy0lEQVR4nO3cOWhWUR7G4ZsY16BGOxVrIY0LSgrBFbRSW7EQrSK4NAYRUlgK2mnsxEq0EVPYKApaiCApFBcwRUDEQpuQCFoo8k0zvM0MDP87Y/JNfJ7+5Vw04ZfTnJ5Op9NpAKBpmt75/gAAuocoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABB98/0B8J/8/v27vJmdnf0DX/K/MTY21mr348eP8mZycrK8uXHjRnkzMjJS3ty9e7e8aZqmWbZsWXlz8eLF8ubSpUvlzULgpgBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQHsRbYD59+lTe/Pz5s7x58eJFefP8+fPypmmaZmZmpry5d+9eq7MWmo0bN5Y3Z8+eLW/Gx8fLm5UrV5Y3TdM0mzdvLm92797d6qy/kZsCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQPR0Op3OfH8E/+rVq1etdvv27StvZmdnW53F3Fq0aFF5c+vWrfKmv7+/vGlj/fr1rXZr1qwpbzZt2tTqrL+RmwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIA4ZXULjU9Pd1qNzQ0VN5MTU21OmuhafNv1+bFzqdPn5Y3TdM0S5YsKW+8gEuVmwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBA9M33B/DvrV27ttXu6tWr5c2DBw/Km61bt5Y3586dK2/a2rJlS3nz5MmT8qa/v7+8effuXXnTNE1z7dq1VjuocFMAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiJ5Op9OZ749gfn379q28WblyZXkzPDxc3jRN09y8ebO8uX37dnlz7Nix8gYWGjcFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgOib7w9g/q1atWpOzlm9evWcnNM07R7RO3r0aHnT2+vvKhYWP9EAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoARE+n0+nM90fwd/j+/Xur3aFDh8qbZ8+elTcPHz4sbw4cOFDeQDdzUwAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAID+LR9aampsqbbdu2lTcDAwPlzd69e8ub7du3lzdN0zSnT58ub3p6elqdxd/LTQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgPIjHgjQ+Pl7enDx5srz59u1bedPW5cuXy5vjx4+XN+vWrStvWDjcFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQDCg3jwT2/fvi1vzp8/X948efKkvGnr1KlT5c3o6Gh5s2HDhvKG7uSmAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABAexIP/wszMTHnz4MGDVmedOHGivGnz671///7y5vHjx+UN3clNAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYDwSir8n1i6dGl58+vXr/Jm8eLF5c2jR4/Kmz179pQ3/HluCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgDRN98fAN3izZs35c29e/fKm4mJifKmado9btfG4OBgebNr164/8CXMBzcFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgPAgHl1vcnKyvLl+/Xp5c//+/fLmy5cv5c1c6uur/4qvW7euvOnt9fflQuF/EoAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACA8iEcrbR6Cu3PnTquzxsbGypuPHz+2Oqub7dixo7wZHR0tbw4fPlzesHC4KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEB/EWmK9fv5Y379+/L2/OnDlT3nz48KG86XZDQ0PlzYULF1qddeTIkfKmt9fffdT4iQEgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgvJI6B6anp8ub4eHhVme9fv26vJmammp1VjfbuXNneXP+/Pny5uDBg+XN8uXLyxuYK24KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCAPFXP4j38uXL8ubKlSvlzcTERHnz+fPn8qbbrVixotXu3Llz5c3o6Gh509/fX97AQuOmAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABB/9YN44+Pjc7KZS4ODg+XNoUOHyptFixaVNyMjI+VN0zTNwMBAqx1Q56YAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAED2dTqcz3x8BQHdwUwAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAg/gEx1gSzbdeSSgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "example_digit = data[0]\n",
    "example_image = data[0].reshape(28, 28)\n",
    "\n",
    "plt.imshow(example_image, cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee0f6bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number '5'\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the number '{0}'\".format(labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f6d5fc",
   "metadata": {},
   "source": [
    "Let's convert label from string to number to make the following processing easier and split training and test data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60fb7b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = labels.astype(np.uint8)\n",
    "\n",
    "NUM_TRAINING_INSTANCES = 60000\n",
    "\n",
    "training_instances = data[:NUM_TRAINING_INSTANCES]\n",
    "training_labels = labels[:NUM_TRAINING_INSTANCES]\n",
    "test_instances = data[NUM_TRAINING_INSTANCES:]\n",
    "test_labels = labels[NUM_TRAINING_INSTANCES:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486a49b",
   "metadata": {},
   "source": [
    "Binary Classifier - Classififying \"5\"\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ab0c7",
   "metadata": {},
   "source": [
    "Let's convert the labels to a boolean type where `True` means \"is 5\" and `False`, otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d23af553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, ...,  True, False, False])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels_5 = (training_labels == 5)\n",
    "test_labels_5 = (test_labels == 5)\n",
    "\n",
    "training_labels_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5d771",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent (SGD) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "525439b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_classifier = SGDClassifier(random_state=42)\n",
    "sgd_classifier.fit(training_instances, training_labels_5)\n",
    "\n",
    "sgd_classifier.predict([example_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5737e4",
   "metadata": {},
   "source": [
    "Performance Measures\n",
    "---------------------------\n",
    "\n",
    "### Cross Validation\n",
    "\n",
    "We use the `cross_val_score()` function to evaluate our `SGDClassifier` model, using K-fold cross-validation with 3 folds. Remember that K-fold cross-validation means splitting the training set into K folds (in this case, 3), then making predictions and evaluating them on each fold using a model trained on the remaining folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a9db133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95035, 0.96035, 0.9604 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_classifier, training_instances, training_labels_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b7d4e8",
   "metadata": {},
   "source": [
    "Occasionally we will need more control over the cross-validation process than what Scikit-Learn provides off the shelf. In these cases, we can implement our own cross-validation. The following code does roughly the same thing as scikit-learn’s `cross_val_score()` function above, and it prints the result in the same ballpark.\n",
    "\n",
    "We use the `StratifiedKFold` class that performs stratified sampling, i.e. to produce folds that contain a representative ratio of each class. At each iteration the code creates a clone of the classifier, trains that clone on the training folds, and makes predictions on the test fold. Then it counts the number of correct predictions and outputs the ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f7c34ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95035\n",
      "0.96035\n",
      "0.9604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in skfolds.split(training_instances, training_labels_5):\n",
    "    sgd_classifier_clone = clone(sgd_classifier)\n",
    "    \n",
    "    training_instances_folds = training_instances[train_index]\n",
    "    training_labels_folds = training_labels_5[train_index]\n",
    "    \n",
    "    test_instances_folds = training_instances[test_index]\n",
    "    test_labels_folds = training_labels_5[test_index]\n",
    "    \n",
    "    sgd_classifier_clone.fit(training_instances_folds, training_labels_folds)\n",
    "    predictions = sgd_classifier_clone.predict(test_instances_folds)\n",
    "    n_correct = sum(predictions == test_labels_folds)\n",
    "    print(n_correct / len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "548a7a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This reault, although looks promising, shows little improvements over baseline given that only about 9.035% of the images are 5's\n"
     ]
    }
   ],
   "source": [
    "prob_5 = len([label for label in training_labels_5 if label == True])/len(training_labels_5)\n",
    "\n",
    "print(\n",
    "    \"This reault, although looks promising, shows little improvements over baseline given that only about \" +\n",
    "    \"{0}% of the images are 5's\".format(prob_5 * 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "316a9db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can have a dummy classifier that always say 'Not a 5' for all training instance that still achive about 90.96499999999999% accuracy\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"We can have a dummy classifier that always say 'Not a 5' for all training instance that still achive about \" +\n",
    "    \"{0}% accuracy\".format((1 - prob_5) * 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befd8357",
   "metadata": {},
   "source": [
    "This demonstrates why __accuracy is generally not the preferred performance measure for classifiers__, especially when we are dealing with _skewed datasets_ (i.e., when some classes are much more frequent than others)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245a174",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d31c6",
   "metadata": {},
   "source": [
    "A much better way to evaluate the performance of a classifier is to look at the __confusion matrix__. The general idea is to count the number of times instances of class A are classified as class B. For example, to know the number of times the classifier confused images of 5s with 3s, we would look in the 5th row and 3rd column of the confusion matrix.\n",
    "\n",
    "We use the `cross_val_predict()` function for this purpose. Just like the `cross_val_score()` used above, `cross_val_predict()` performs K-fold cross-validation, but instead of returning the evaluation scores, it returns the predictions made on each test fold. This means that you get a clean prediction for each instance in the training set (“clean” meaning that the prediction is made by a model that never saw the data during training).\n",
    "\n",
    "We assign the clean prediction to a variable named `predictions` which essentially contains the predicted labels for each training instance. Then we use `confusion_matrix()` to get the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95b94e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53892,   687],\n",
       "       [ 1891,  3530]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "predicitons = cross_val_predict(sgd_classifier, training_instances, training_labels_5, cv=3)\n",
    "confusion_matrix(training_labels_5, predicitons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adbbc53",
   "metadata": {},
   "source": [
    "Each row in a confusion matrix represents an labeled class, while each column repre‐ sents a predicted class.\n",
    "\n",
    "- The first row of this matrix considers non-5 images (the negative class)\n",
    "\n",
    "  - The 1st element is the the number of non-5's correctly classified (_true negatives_ or __TN__)\n",
    "  - The 2nd element is the the number of non-5's misclassified (_false positive_ or __FP__)\n",
    "  \n",
    "- The second row considers images of 5's (the positive class)\n",
    "\n",
    "  - The 1st element is the number of misclassified non-5's (_false negative_ or __FN__)\n",
    "  - The 2nd element is the number of correctly classified 5's (_true positive_ or __TP__)\n",
    "  \n",
    "A perfect classifier would have only true positives and true negatives, so __its confusion matrix would have nonzero values only on its main diagonal__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c953b199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
